{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9359231,"sourceType":"datasetVersion","datasetId":5674388}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import h5py\nimport pandas as pd\nfrom sklearn.utils import resample\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\nimport torch\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, roc_curve, auc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import label_binarize\n\n# Function to load and process the HDF5 file\ndef load_and_process_hdf5(file_path):\n    with h5py.File(file_path, 'r') as hdf:\n        # List all keys\n        print(f\"Keys in {file_path}: {list(hdf.keys())}\")\n\n        # Load the datasets into pandas Series\n        cwe_119_data = pd.Series(hdf['CWE-119'][:], name='CWE-119')\n        cwe_120_data = pd.Series(hdf['CWE-120'][:], name='CWE-120')\n        cwe_469_data = pd.Series(hdf['CWE-469'][:], name='CWE-469')\n        cwe_476_data = pd.Series(hdf['CWE-476'][:], name='CWE-476')\n        cwe_other_data = pd.Series(hdf['CWE-other'][:], name='CWE-other')\n        function_source_data = pd.Series(hdf['functionSource'][:], name='functionSource')\n\n    # Create a DataFrame with the boolean columns\n    df = pd.concat([cwe_119_data, cwe_120_data, cwe_469_data, cwe_476_data, cwe_other_data], axis=1)\n\n    # Create a new column 'Class' based on the boolean columns\n    def assign_class(row):\n        if row['CWE-119']:\n            return 0\n        elif row['CWE-120']:\n            return 1\n        elif row['CWE-469']:\n            return 2\n        elif row['CWE-476']:\n            return 3\n        elif row['CWE-other']:\n            return 4\n        else:\n            return -1  # In case none of the columns are True\n\n    df['Class'] = df.apply(assign_class, axis=1)\n\n    # Now eliminate rows where Class = -1 and the corresponding functionSource\n    mask = df['Class'] != -1\n    df_filtered = df[mask]\n    function_source_filtered = function_source_data[mask]\n\n    # Combine the filtered Class and functionSource data\n    df_final = pd.concat([df_filtered['Class'], function_source_filtered], axis=1)\n\n    return df_final","metadata":{"execution":{"iopub.status.busy":"2024-09-10T11:43:25.375615Z","iopub.execute_input":"2024-09-10T11:43:25.376658Z","iopub.status.idle":"2024-09-10T11:43:45.919267Z","shell.execute_reply.started":"2024-09-10T11:43:25.376605Z","shell.execute_reply":"2024-09-10T11:43:45.918170Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Paths to your HDF5 files\ntrain_hdf5_file_path = '/kaggle/input/vulnerabilitycode/VDISC_train.hdf5'\ntest_hdf5_file_path = '/kaggle/input/vulnerabilitycode/VDISC_test.hdf5'\nvalidation_hdf5_file_path = '/kaggle/input/vulnerabilitycode/VDISC_validate.hdf5'\n\n# Process the training dataset\nprint(\"Processing Training Dataset:\")\ndf_train_final = load_and_process_hdf5(train_hdf5_file_path)\n\n# Downsample training set to 20,000 samples with the given proportions\ntrain_sample_proportions = {0: 5942, 1: 5777, 4: 5582, 3: 2755, 2: 249}  # Based on your request\ndf_train_downsampled = pd.DataFrame()\nfor cls, n_samples in train_sample_proportions.items():\n    class_data = df_train_final[df_train_final['Class'] == cls]\n    class_downsampled = resample(class_data, replace=False, n_samples=n_samples, random_state=42)\n    df_train_downsampled = pd.concat([df_train_downsampled, class_downsampled])\n\nprint(\"Final Training Data Class Distribution:\")\nprint(df_train_downsampled['Class'].value_counts())\n\n# Process the validation dataset and downsample to 3,900 samples\nprint(\"\\nProcessing Validation Dataset:\")\ndf_val_final = load_and_process_hdf5(validation_hdf5_file_path)\nval_sample_proportions = {0: 1142, 1: 1099, 4: 1071, 3: 535, 2: 53}  # Recalculated for 3900 samples\ndf_val_downsampled = pd.DataFrame()\nfor cls, n_samples in val_sample_proportions.items():\n    class_data = df_val_final[df_val_final['Class'] == cls]\n    class_downsampled = resample(class_data, replace=False, n_samples=n_samples, random_state=42)\n    df_val_downsampled = pd.concat([df_val_downsampled, class_downsampled])\n\nprint(\"Final Validation Data Class Distribution:\")\nprint(df_val_downsampled['Class'].value_counts())\n\n# Process the test dataset and downsample to 3,900 samples\nprint(\"\\nProcessing Test Dataset:\")\ndf_test_final = load_and_process_hdf5(test_hdf5_file_path)\ntest_sample_proportions = {0: 1142, 1: 1099, 4: 1071, 3: 535, 2: 53}  # Recalculated for 3900 samples\ndf_test_downsampled = pd.DataFrame()\nfor cls, n_samples in test_sample_proportions.items():\n    class_data = df_test_final[df_test_final['Class'] == cls]\n    class_downsampled = resample(class_data, replace=False, n_samples=n_samples, random_state=42)\n    df_test_downsampled = pd.concat([df_test_downsampled, class_downsampled])\n\nprint(\"Final Test Data Class Distribution:\")\nprint(df_test_downsampled['Class'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T11:43:45.921382Z","iopub.execute_input":"2024-09-10T11:43:45.922221Z","iopub.status.idle":"2024-09-10T11:44:30.680823Z","shell.execute_reply.started":"2024-09-10T11:43:45.922176Z","shell.execute_reply":"2024-09-10T11:44:30.679728Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Processing Training Dataset:\nKeys in /kaggle/input/vulnerabilitycode/VDISC_train.hdf5: ['CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'functionSource']\nFinal Training Data Class Distribution:\nClass\n0    5942\n1    5777\n4    5582\n3    2755\n2     249\nName: count, dtype: int64\n\nProcessing Validation Dataset:\nKeys in /kaggle/input/vulnerabilitycode/VDISC_validate.hdf5: ['CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'functionSource']\nFinal Validation Data Class Distribution:\nClass\n0    1142\n1    1099\n4    1071\n3     535\n2      53\nName: count, dtype: int64\n\nProcessing Test Dataset:\nKeys in /kaggle/input/vulnerabilitycode/VDISC_test.hdf5: ['CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'functionSource']\nFinal Test Data Class Distribution:\nClass\n0    1142\n1    1099\n4    1071\n3     535\n2      53\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report\nfrom sklearn.preprocessing import label_binarize\nimport numpy as np\nimport pandas as pd\n\n# Custom Dataset class to handle encodings and labels\nclass UniXcoderDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        # Convert inputs and labels to tensors\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Function to tokenize the function source code for training, validation, and test datasets\ndef tokenize_function(df):\n    return tokenizer(\n        df['functionSource'].astype(str).tolist(),\n        padding=True,\n        truncation=True,\n        max_length=512,\n        return_tensors='pt'\n    )\n\n# Load the pre-trained UniXcoder tokenizer\ntokenizer = RobertaTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n\n# Apply the tokenization on the datasets\ntrain_encodings = tokenize_function(df_train_downsampled)\nval_encodings = tokenize_function(df_val_downsampled)\ntest_encodings = tokenize_function(df_test_downsampled)\n\n# Prepare labels\ntrain_labels = df_train_downsampled['Class'].tolist()\nval_labels = df_val_downsampled['Class'].tolist()\ntest_labels = df_test_downsampled['Class'].tolist()\n\n# Create Dataset objects for training, validation, and test datasets\ntrain_dataset = UniXcoderDataset(train_encodings, train_labels)\nval_dataset = UniXcoderDataset(val_encodings, val_labels)\ntest_dataset = UniXcoderDataset(test_encodings, test_labels)\n\n# Define compute_metrics function to calculate accuracy, precision, recall, F1, ROC-AUC, and final classification report\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n\n    # Precision, Recall, F1\n    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n    acc = accuracy_score(p.label_ids, preds)\n\n    # Compute ROC-AUC for multi-class classification\n    label_binarized = label_binarize(p.label_ids, classes=[0, 1, 2, 3, 4])\n    auc_score = roc_auc_score(\n        y_true=label_binarized,\n        y_score=p.predictions,\n        multi_class=\"ovr\"\n    )\n    \n    # Full classification report (output as a dictionary)\n    report_dict = classification_report(p.label_ids, preds, target_names=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'], output_dict=True)\n    \n    # Convert to DataFrame for easy rounding and formatting\n    report_df = pd.DataFrame(report_dict).transpose()\n    report_df = report_df.round(4)  # Round to 4 decimal places\n    \n    print(\"\\nFinal Classification Report (rounded to 4 decimal places):\\n\", report_df)\n\n    return {\n        'accuracy': acc,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'roc_auc': auc_score\n    }\n\n# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy='epoch',\n    per_device_train_batch_size=16,  # Adjust batch size based on available GPU\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,  # Increase to 4-5 epochs if needed\n    learning_rate=2e-5,  # Standard learning rate for fine-tuning transformers\n    logging_dir='./logs',\n    logging_steps=10,\n    save_steps=500,\n    save_total_limit=2,  # Save only the 2 most recent models\n    report_to=\"none\"  # Disable Weights & Biases (wandb) logging\n)\n\n# Load the pre-trained UniXcoder model for classification\nmodel = RobertaForSequenceClassification.from_pretrained(\"microsoft/unixcoder-base\", num_labels=5)\n\n# Trainer setup\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,  # Custom training dataset\n    eval_dataset=val_dataset,  # Custom validation dataset\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics  # Metrics function for accuracy, precision, recall, F1, ROC-AUC, classification report\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate the model on the test dataset\nresults = trainer.evaluate(eval_dataset=test_dataset)  # Custom test dataset\nprint(results)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T11:44:30.682269Z","iopub.execute_input":"2024-09-10T11:44:30.682565Z","iopub.status.idle":"2024-09-10T12:45:19.216075Z","shell.execute_reply.started":"2024-09-10T11:44:30.682533Z","shell.execute_reply":"2024-09-10T12:45:19.215034Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"823c6dd0631642068ba466e3dd0fa490"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/938k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b2be70dcf5d4f7dbc6dde01e2ce23bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/444k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d84bea8a5af54eedb53e77b5e660dd6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85f41b16094a4cbabe32244aa920c19f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/691 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"267690404ae343979e6074f09be3747b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/504M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed18fba520d484aaaa851110d517401"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/unixcoder-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3810' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3810/3810 57:30, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.793900</td>\n      <td>0.613832</td>\n      <td>0.796410</td>\n      <td>0.798206</td>\n      <td>0.796410</td>\n      <td>0.795769</td>\n      <td>0.923464</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.499700</td>\n      <td>0.575630</td>\n      <td>0.806154</td>\n      <td>0.806527</td>\n      <td>0.806154</td>\n      <td>0.804033</td>\n      <td>0.931404</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.348000</td>\n      <td>0.604110</td>\n      <td>0.810000</td>\n      <td>0.807359</td>\n      <td>0.810000</td>\n      <td>0.807958</td>\n      <td>0.933134</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score    support\nClass 0          0.8742  0.8827    0.8784  1142.0000\nClass 1          0.8687  0.8371    0.8526  1099.0000\nClass 2          0.5312  0.3208    0.4000    53.0000\nClass 3          0.7489  0.6467    0.6941   535.0000\nClass 4          0.6826  0.7610    0.7196  1071.0000\naccuracy         0.7964  0.7964    0.7964     0.7964\nmacro avg        0.7411  0.6896    0.7090  3900.0000\nweighted avg     0.7982  0.7964    0.7958  3900.0000\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score    support\nClass 0          0.8544  0.8940    0.8738  1142.0000\nClass 1          0.8604  0.8690    0.8646  1099.0000\nClass 2          0.6176  0.3962    0.4828    53.0000\nClass 3          0.8116  0.6280    0.7081   535.0000\nClass 4          0.7071  0.7572    0.7313  1071.0000\naccuracy         0.8062  0.8062    0.8062     0.8062\nmacro avg        0.7702  0.7089    0.7321  3900.0000\nweighted avg     0.8065  0.8062    0.8040  3900.0000\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score  support\nClass 0          0.8685  0.8905    0.8794  1142.00\nClass 1          0.8417  0.8808    0.8608  1099.00\nClass 2          0.6000  0.3962    0.4773    53.00\nClass 3          0.7614  0.6860    0.7217   535.00\nClass 4          0.7401  0.7339    0.7370  1071.00\naccuracy         0.8100  0.8100    0.8100     0.81\nmacro avg        0.7624  0.7175    0.7352  3900.00\nweighted avg     0.8074  0.8100    0.8080  3900.00\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/695130745.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='244' max='244' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [244/244 01:09]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score    support\nClass 0          0.8833  0.8748    0.8790  1142.0000\nClass 1          0.8279  0.8799    0.8531  1099.0000\nClass 2          0.4828  0.2642    0.3415    53.0000\nClass 3          0.7980  0.7308    0.7629   535.0000\nClass 4          0.7338  0.7414    0.7376  1071.0000\naccuracy         0.8115  0.8115    0.8115     0.8115\nmacro avg        0.7451  0.6982    0.7148  3900.0000\nweighted avg     0.8095  0.8115    0.8096  3900.0000\n{'eval_loss': 0.6207788586616516, 'eval_accuracy': 0.8115384615384615, 'eval_precision': 0.8094904117036521, 'eval_recall': 0.8115384615384615, 'eval_f1': 0.8096433435889524, 'eval_roc_auc': 0.9228311086643176, 'eval_runtime': 69.7183, 'eval_samples_per_second': 55.939, 'eval_steps_per_second': 3.5, 'epoch': 3.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\n# Plot AUC-ROC curves for each class and save the figure\ndef plot_roc_auc_curve(test_labels, predictions, num_classes=5):\n    test_labels_bin = label_binarize(test_labels, classes=[0, 1, 2, 3, 4])  # Binarize the labels for multi-class ROC\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(test_labels_bin[:, i], predictions[:, i])\n        roc_auc[i] = roc_auc_score(test_labels_bin[:, i], predictions[:, i])\n\n    # Plot ROC curve for each class\n    plt.figure(figsize=(10, 8))\n    colors = ['aqua', 'darkorange', 'cornflowerblue', 'green', 'red']\n    for i in range(num_classes):\n        plt.plot(fpr[i], tpr[i], color=colors[i], lw=2,\n                 label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')\n\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) for each class')\n    plt.legend(loc=\"lower right\")\n\n    # Save the figure to a file\n    output_dir = './roc_auc_plots'\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    plt.savefig(os.path.join(output_dir, 'roc_auc_curve.png'))  # Save the figure as PNG\n    plt.show()\n\n# Compute metrics function with ROC-AUC curve plotting and saving\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n    \n    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n    acc = accuracy_score(p.label_ids, preds)\n    \n    # Compute ROC-AUC for each class using one-vs-rest approach\n    label_binarized = label_binarize(p.label_ids, classes=[0, 1, 2, 3, 4])\n    auc_score = roc_auc_score(\n        y_true=label_binarized,\n        y_score=p.predictions,\n        multi_class=\"ovr\"\n    )\n\n    # Plot ROC curves for each class and save to a file\n    plot_roc_auc_curve(p.label_ids, p.predictions)\n\n    return {\n        'accuracy': acc,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'roc_auc': auc_score\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T12:45:19.218110Z","iopub.execute_input":"2024-09-10T12:45:19.218431Z","iopub.status.idle":"2024-09-10T12:45:19.231911Z","shell.execute_reply.started":"2024-09-10T12:45:19.218397Z","shell.execute_reply":"2024-09-10T12:45:19.230941Z"},"trusted":true},"execution_count":4,"outputs":[]}]}