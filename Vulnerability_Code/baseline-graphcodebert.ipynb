{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9359208,"sourceType":"datasetVersion","datasetId":5674369}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import h5py\nimport pandas as pd\nfrom sklearn.utils import resample\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\nimport torch\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, roc_curve, auc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import label_binarize\n\n# Function to load and process the HDF5 file\ndef load_and_process_hdf5(file_path):\n    with h5py.File(file_path, 'r') as hdf:\n        # List all keys\n        print(f\"Keys in {file_path}: {list(hdf.keys())}\")\n\n        # Load the datasets into pandas Series\n        cwe_119_data = pd.Series(hdf['CWE-119'][:], name='CWE-119')\n        cwe_120_data = pd.Series(hdf['CWE-120'][:], name='CWE-120')\n        cwe_469_data = pd.Series(hdf['CWE-469'][:], name='CWE-469')\n        cwe_476_data = pd.Series(hdf['CWE-476'][:], name='CWE-476')\n        cwe_other_data = pd.Series(hdf['CWE-other'][:], name='CWE-other')\n        function_source_data = pd.Series(hdf['functionSource'][:], name='functionSource')\n\n    # Create a DataFrame with the boolean columns\n    df = pd.concat([cwe_119_data, cwe_120_data, cwe_469_data, cwe_476_data, cwe_other_data], axis=1)\n\n    # Create a new column 'Class' based on the boolean columns\n    def assign_class(row):\n        if row['CWE-119']:\n            return 0\n        elif row['CWE-120']:\n            return 1\n        elif row['CWE-469']:\n            return 2\n        elif row['CWE-476']:\n            return 3\n        elif row['CWE-other']:\n            return 4\n        else:\n            return -1  # In case none of the columns are True\n\n    df['Class'] = df.apply(assign_class, axis=1)\n\n    # Now eliminate rows where Class = -1 and the corresponding functionSource\n    mask = df['Class'] != -1\n    df_filtered = df[mask]\n    function_source_filtered = function_source_data[mask]\n\n    # Combine the filtered Class and functionSource data\n    df_final = pd.concat([df_filtered['Class'], function_source_filtered], axis=1)\n\n    return df_final","metadata":{"execution":{"iopub.status.busy":"2024-09-10T11:42:44.158394Z","iopub.execute_input":"2024-09-10T11:42:44.158793Z","iopub.status.idle":"2024-09-10T11:43:03.324292Z","shell.execute_reply.started":"2024-09-10T11:42:44.158755Z","shell.execute_reply":"2024-09-10T11:43:03.323222Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Paths to your HDF5 files\ntrain_hdf5_file_path = '/kaggle/input/vulnerabilitycode/VDISC_train.hdf5'\ntest_hdf5_file_path = '/kaggle/input/vulnerabilitycode/VDISC_test.hdf5'\nvalidation_hdf5_file_path = '/kaggle/input/vulnerabilitycode/VDISC_validate.hdf5'\n\n# Process the training dataset\nprint(\"Processing Training Dataset:\")\ndf_train_final = load_and_process_hdf5(train_hdf5_file_path)\n\n# Downsample training set to 20,000 samples with the given proportions\ntrain_sample_proportions = {0: 5942, 1: 5777, 4: 5582, 3: 2755, 2: 249}  # Based on your request\ndf_train_downsampled = pd.DataFrame()\nfor cls, n_samples in train_sample_proportions.items():\n    class_data = df_train_final[df_train_final['Class'] == cls]\n    class_downsampled = resample(class_data, replace=False, n_samples=n_samples, random_state=42)\n    df_train_downsampled = pd.concat([df_train_downsampled, class_downsampled])\n\nprint(\"Final Training Data Class Distribution:\")\nprint(df_train_downsampled['Class'].value_counts())\n\n# Process the validation dataset and downsample to 3,900 samples\nprint(\"\\nProcessing Validation Dataset:\")\ndf_val_final = load_and_process_hdf5(validation_hdf5_file_path)\nval_sample_proportions = {0: 1142, 1: 1099, 4: 1071, 3: 535, 2: 53}  # Recalculated for 3900 samples\ndf_val_downsampled = pd.DataFrame()\nfor cls, n_samples in val_sample_proportions.items():\n    class_data = df_val_final[df_val_final['Class'] == cls]\n    class_downsampled = resample(class_data, replace=False, n_samples=n_samples, random_state=42)\n    df_val_downsampled = pd.concat([df_val_downsampled, class_downsampled])\n\nprint(\"Final Validation Data Class Distribution:\")\nprint(df_val_downsampled['Class'].value_counts())\n\n# Process the test dataset and downsample to 3,900 samples\nprint(\"\\nProcessing Test Dataset:\")\ndf_test_final = load_and_process_hdf5(test_hdf5_file_path)\ntest_sample_proportions = {0: 1142, 1: 1099, 4: 1071, 3: 535, 2: 53}  # Recalculated for 3900 samples\ndf_test_downsampled = pd.DataFrame()\nfor cls, n_samples in test_sample_proportions.items():\n    class_data = df_test_final[df_test_final['Class'] == cls]\n    class_downsampled = resample(class_data, replace=False, n_samples=n_samples, random_state=42)\n    df_test_downsampled = pd.concat([df_test_downsampled, class_downsampled])\n\nprint(\"Final Test Data Class Distribution:\")\nprint(df_test_downsampled['Class'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T11:43:03.326246Z","iopub.execute_input":"2024-09-10T11:43:03.326875Z","iopub.status.idle":"2024-09-10T11:43:58.328363Z","shell.execute_reply.started":"2024-09-10T11:43:03.326840Z","shell.execute_reply":"2024-09-10T11:43:58.327398Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Processing Training Dataset:\nKeys in /kaggle/input/vulnerabilitycode/VDISC_train.hdf5: ['CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'functionSource']\nFinal Training Data Class Distribution:\nClass\n0    5942\n1    5777\n4    5582\n3    2755\n2     249\nName: count, dtype: int64\n\nProcessing Validation Dataset:\nKeys in /kaggle/input/vulnerabilitycode/VDISC_validate.hdf5: ['CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'functionSource']\nFinal Validation Data Class Distribution:\nClass\n0    1142\n1    1099\n4    1071\n3     535\n2      53\nName: count, dtype: int64\n\nProcessing Test Dataset:\nKeys in /kaggle/input/vulnerabilitycode/VDISC_test.hdf5: ['CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'functionSource']\nFinal Test Data Class Distribution:\nClass\n0    1142\n1    1099\n4    1071\n3     535\n2      53\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report\nfrom sklearn.preprocessing import label_binarize\nimport numpy as np\nimport pandas as pd\n\n# Custom Dataset class to handle encodings and labels\nclass GraphCodeBERTDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        # Convert inputs and labels to tensors\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Function to tokenize the function source code for training, validation, and test datasets\ndef tokenize_function(df):\n    return tokenizer(\n        df['functionSource'].astype(str).tolist(),\n        padding=True,\n        truncation=True,\n        max_length=512,\n        return_tensors='pt'\n    )\n\n# Load the pre-trained GraphCodeBERT tokenizer\ntokenizer = RobertaTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n\n# Apply the tokenization on the datasets\ntrain_encodings = tokenize_function(df_train_downsampled)\nval_encodings = tokenize_function(df_val_downsampled)\ntest_encodings = tokenize_function(df_test_downsampled)\n\n# Prepare labels\ntrain_labels = df_train_downsampled['Class'].tolist()\nval_labels = df_val_downsampled['Class'].tolist()\ntest_labels = df_test_downsampled['Class'].tolist()\n\n# Create Dataset objects for training, validation, and test datasets\ntrain_dataset = GraphCodeBERTDataset(train_encodings, train_labels)\nval_dataset = GraphCodeBERTDataset(val_encodings, val_labels)\ntest_dataset = GraphCodeBERTDataset(test_encodings, test_labels)\n\n# Define compute_metrics function to calculate accuracy, precision, recall, F1, ROC-AUC, and final classification report\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n\n    # Precision, Recall, F1\n    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n    acc = accuracy_score(p.label_ids, preds)\n\n    # Compute ROC-AUC for multi-class classification\n    label_binarized = label_binarize(p.label_ids, classes=[0, 1, 2, 3, 4])\n    auc_score = roc_auc_score(\n        y_true=label_binarized,\n        y_score=p.predictions,\n        multi_class=\"ovr\"\n    )\n    \n    # Full classification report (output as a dictionary)\n    report_dict = classification_report(p.label_ids, preds, target_names=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'], output_dict=True)\n    \n    # Convert to DataFrame for easy rounding and formatting\n    report_df = pd.DataFrame(report_dict).transpose()\n    report_df = report_df.round(4)  # Round to 4 decimal places\n    \n    print(\"\\nFinal Classification Report (rounded to 4 decimal places):\\n\", report_df)\n\n    return {\n        'accuracy': acc,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'roc_auc': auc_score\n    }\n\n# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy='epoch',\n    per_device_train_batch_size=16,  # Adjust batch size based on available GPU\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,  # Increase to 4-5 epochs if needed\n    learning_rate=2e-5,  # Standard learning rate for fine-tuning transformers\n    logging_dir='./logs',\n    logging_steps=10,\n    save_steps=500,\n    save_total_limit=2,  # Save only the 2 most recent models\n    report_to=\"none\"  # Disable Weights & Biases (wandb) logging\n)\n\n# Load the pre-trained GraphCodeBERT model for classification\nmodel = RobertaForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\", num_labels=5)\n\n# Trainer setup\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,  # Custom training dataset\n    eval_dataset=val_dataset,  # Custom validation dataset\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics  # Metrics function for accuracy, precision, recall, F1, ROC-AUC, classification report\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate the model on the test dataset\nresults = trainer.evaluate(eval_dataset=test_dataset)  # Custom test dataset\nprint(results)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T11:43:58.330038Z","iopub.execute_input":"2024-09-10T11:43:58.330438Z","iopub.status.idle":"2024-09-10T12:44:20.948457Z","shell.execute_reply.started":"2024-09-10T11:43:58.330393Z","shell.execute_reply":"2024-09-10T12:44:20.947546Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"266dd86e7d8a4b0caf02642f96e18549"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820e5328ab514fdd9a09637009c9eca2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a496bb963f47aa9bd79062fb08ce08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21392a0a0d5e41aebdbed97256d7e6a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/539 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47ce7259968a4941a0dff8cf226101ec"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94b24fd55e3e40a2bb8f8bb511541f09"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3810' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3810/3810 57:09, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.778000</td>\n      <td>0.628081</td>\n      <td>0.780256</td>\n      <td>0.790190</td>\n      <td>0.780256</td>\n      <td>0.781320</td>\n      <td>0.916174</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.548600</td>\n      <td>0.598903</td>\n      <td>0.791795</td>\n      <td>0.790465</td>\n      <td>0.791795</td>\n      <td>0.789037</td>\n      <td>0.925929</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.413900</td>\n      <td>0.605876</td>\n      <td>0.792821</td>\n      <td>0.789150</td>\n      <td>0.792821</td>\n      <td>0.789578</td>\n      <td>0.927058</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score    support\nClass 0          0.8855  0.8669    0.8761  1142.0000\nClass 1          0.8747  0.7880    0.8291  1099.0000\nClass 2          0.5000  0.2830    0.3614    53.0000\nClass 3          0.7489  0.6243    0.6809   535.0000\nClass 4          0.6368  0.7824    0.7021  1071.0000\naccuracy         0.7803  0.7803    0.7803     0.7803\nmacro avg        0.7292  0.6689    0.6899  3900.0000\nweighted avg     0.7902  0.7803    0.7813  3900.0000\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score    support\nClass 0          0.8622  0.8879    0.8749  1142.0000\nClass 1          0.8232  0.8644    0.8433  1099.0000\nClass 2          0.4545  0.2830    0.3488    53.0000\nClass 3          0.7981  0.6206    0.6982   535.0000\nClass 4          0.6931  0.7255    0.7089  1071.0000\naccuracy         0.7918  0.7918    0.7918     0.7918\nmacro avg        0.7262  0.6763    0.6948  3900.0000\nweighted avg     0.7905  0.7918    0.7890  3900.0000\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score    support\nClass 0          0.8585  0.8870    0.8725  1142.0000\nClass 1          0.8020  0.8844    0.8412  1099.0000\nClass 2          0.4500  0.3396    0.3871    53.0000\nClass 3          0.7628  0.6673    0.7119   535.0000\nClass 4          0.7320  0.6835    0.7069  1071.0000\naccuracy         0.7928  0.7928    0.7928     0.7928\nmacro avg        0.7211  0.6924    0.7039  3900.0000\nweighted avg     0.7892  0.7928    0.7896  3900.0000\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/2785395744.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='244' max='244' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [244/244 01:09]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score    support\nClass 0          0.8841  0.8616    0.8727  1142.0000\nClass 1          0.7993  0.8772    0.8364  1099.0000\nClass 2          0.4412  0.2830    0.3448    53.0000\nClass 3          0.7862  0.7215    0.7524   535.0000\nClass 4          0.7244  0.7143    0.7193  1071.0000\naccuracy         0.7985  0.7985    0.7985     0.7985\nmacro avg        0.7270  0.6915    0.7052  3900.0000\nweighted avg     0.7969  0.7985    0.7967  3900.0000\n{'eval_loss': 0.6165109872817993, 'eval_accuracy': 0.7984615384615384, 'eval_precision': 0.7969100651373761, 'eval_recall': 0.7984615384615384, 'eval_f1': 0.7966998106581769, 'eval_roc_auc': 0.9192607216384834, 'eval_runtime': 69.6355, 'eval_samples_per_second': 56.006, 'eval_steps_per_second': 3.504, 'epoch': 3.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\n# Plot AUC-ROC curves for each class and save the figure\ndef plot_roc_auc_curve(test_labels, predictions, num_classes=5):\n    test_labels_bin = label_binarize(test_labels, classes=[0, 1, 2, 3, 4])  # Binarize the labels for multi-class ROC\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(test_labels_bin[:, i], predictions[:, i])\n        roc_auc[i] = roc_auc_score(test_labels_bin[:, i], predictions[:, i])\n\n    # Plot ROC curve for each class\n    plt.figure(figsize=(10, 8))\n    colors = ['aqua', 'darkorange', 'cornflowerblue', 'green', 'red']\n    for i in range(num_classes):\n        plt.plot(fpr[i], tpr[i], color=colors[i], lw=2,\n                 label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')\n\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) for each class')\n    plt.legend(loc=\"lower right\")\n\n    # Save the figure to a file\n    output_dir = './roc_auc_plots'\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    plt.savefig(os.path.join(output_dir, 'roc_auc_curve.png'))  # Save the figure as PNG\n    plt.show()\n\n# Compute metrics function with ROC-AUC curve plotting and saving\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n    \n    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n    acc = accuracy_score(p.label_ids, preds)\n    \n    # Compute ROC-AUC for each class using one-vs-rest approach\n    label_binarized = label_binarize(p.label_ids, classes=[0, 1, 2, 3, 4])\n    auc_score = roc_auc_score(\n        y_true=label_binarized,\n        y_score=p.predictions,\n        multi_class=\"ovr\"\n    )\n\n    # Plot ROC curves for each class and save to a file\n    plot_roc_auc_curve(p.label_ids, p.predictions)\n\n    return {\n        'accuracy': acc,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'roc_auc': auc_score\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T12:44:20.949727Z","iopub.execute_input":"2024-09-10T12:44:20.950058Z","iopub.status.idle":"2024-09-10T12:44:20.964238Z","shell.execute_reply.started":"2024-09-10T12:44:20.950024Z","shell.execute_reply":"2024-09-10T12:44:20.963337Z"},"trusted":true},"execution_count":4,"outputs":[]}]}