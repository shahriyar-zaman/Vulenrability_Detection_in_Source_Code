{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9357799,"sourceType":"datasetVersion","datasetId":5673253}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import h5py\nimport pandas as pd\nfrom sklearn.utils import resample\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\nimport torch\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, roc_curve, auc\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import label_binarize\n\n# Function to load and process the HDF5 file\ndef load_and_process_hdf5(file_path):\n    with h5py.File(file_path, 'r') as hdf:\n        # List all keys\n        print(f\"Keys in {file_path}: {list(hdf.keys())}\")\n\n        # Load the datasets into pandas Series\n        cwe_119_data = pd.Series(hdf['CWE-119'][:], name='CWE-119')\n        cwe_120_data = pd.Series(hdf['CWE-120'][:], name='CWE-120')\n        cwe_469_data = pd.Series(hdf['CWE-469'][:], name='CWE-469')\n        cwe_476_data = pd.Series(hdf['CWE-476'][:], name='CWE-476')\n        cwe_other_data = pd.Series(hdf['CWE-other'][:], name='CWE-other')\n        function_source_data = pd.Series(hdf['functionSource'][:], name='functionSource')\n\n    # Create a DataFrame with the boolean columns\n    df = pd.concat([cwe_119_data, cwe_120_data, cwe_469_data, cwe_476_data, cwe_other_data], axis=1)\n\n    # Create a new column 'Class' based on the boolean columns\n    def assign_class(row):\n        if row['CWE-119']:\n            return 0\n        elif row['CWE-120']:\n            return 1\n        elif row['CWE-469']:\n            return 2\n        elif row['CWE-476']:\n            return 3\n        elif row['CWE-other']:\n            return 4\n        else:\n            return -1  # In case none of the columns are True\n\n    df['Class'] = df.apply(assign_class, axis=1)\n\n    # Now eliminate rows where Class = -1 and the corresponding functionSource\n    mask = df['Class'] != -1\n    df_filtered = df[mask]\n    function_source_filtered = function_source_data[mask]\n\n    # Combine the filtered Class and functionSource data\n    df_final = pd.concat([df_filtered['Class'], function_source_filtered], axis=1)\n\n    return df_final","metadata":{"execution":{"iopub.status.busy":"2024-09-10T11:24:16.559630Z","iopub.execute_input":"2024-09-10T11:24:16.560567Z","iopub.status.idle":"2024-09-10T11:24:38.686782Z","shell.execute_reply.started":"2024-09-10T11:24:16.560508Z","shell.execute_reply":"2024-09-10T11:24:38.685663Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Paths to your HDF5 files\ntrain_hdf5_file_path = '/kaggle/input/vulnerabilitycode/VDISC_train.hdf5'\ntest_hdf5_file_path = '/kaggle/input/vulnerabilitycode/VDISC_test.hdf5'\nvalidation_hdf5_file_path = '/kaggle/input/vulnerabilitycode/VDISC_validate.hdf5'\n\n# Process the training dataset\nprint(\"Processing Training Dataset:\")\ndf_train_final = load_and_process_hdf5(train_hdf5_file_path)\n\n# Downsample training set to 20,000 samples with the given proportions\ntrain_sample_proportions = {0: 5942, 1: 5777, 4: 5582, 3: 2755, 2: 249}  # Based on your request\ndf_train_downsampled = pd.DataFrame()\nfor cls, n_samples in train_sample_proportions.items():\n    class_data = df_train_final[df_train_final['Class'] == cls]\n    class_downsampled = resample(class_data, replace=False, n_samples=n_samples, random_state=42)\n    df_train_downsampled = pd.concat([df_train_downsampled, class_downsampled])\n\nprint(\"Final Training Data Class Distribution:\")\nprint(df_train_downsampled['Class'].value_counts())\n\n# Process the validation dataset and downsample to 3,900 samples\nprint(\"\\nProcessing Validation Dataset:\")\ndf_val_final = load_and_process_hdf5(validation_hdf5_file_path)\nval_sample_proportions = {0: 1142, 1: 1099, 4: 1071, 3: 535, 2: 53}  # Recalculated for 3900 samples\ndf_val_downsampled = pd.DataFrame()\nfor cls, n_samples in val_sample_proportions.items():\n    class_data = df_val_final[df_val_final['Class'] == cls]\n    class_downsampled = resample(class_data, replace=False, n_samples=n_samples, random_state=42)\n    df_val_downsampled = pd.concat([df_val_downsampled, class_downsampled])\n\nprint(\"Final Validation Data Class Distribution:\")\nprint(df_val_downsampled['Class'].value_counts())\n\n# Process the test dataset and downsample to 3,900 samples\nprint(\"\\nProcessing Test Dataset:\")\ndf_test_final = load_and_process_hdf5(test_hdf5_file_path)\ntest_sample_proportions = {0: 1142, 1: 1099, 4: 1071, 3: 535, 2: 53}  # Recalculated for 3900 samples\ndf_test_downsampled = pd.DataFrame()\nfor cls, n_samples in test_sample_proportions.items():\n    class_data = df_test_final[df_test_final['Class'] == cls]\n    class_downsampled = resample(class_data, replace=False, n_samples=n_samples, random_state=42)\n    df_test_downsampled = pd.concat([df_test_downsampled, class_downsampled])\n\nprint(\"Final Test Data Class Distribution:\")\nprint(df_test_downsampled['Class'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T11:24:38.689236Z","iopub.execute_input":"2024-09-10T11:24:38.690436Z","iopub.status.idle":"2024-09-10T11:25:29.166530Z","shell.execute_reply.started":"2024-09-10T11:24:38.690380Z","shell.execute_reply":"2024-09-10T11:25:29.165407Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Processing Training Dataset:\nKeys in /kaggle/input/vulnerabilitycode/VDISC_train.hdf5: ['CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'functionSource']\nFinal Training Data Class Distribution:\nClass\n0    5942\n1    5777\n4    5582\n3    2755\n2     249\nName: count, dtype: int64\n\nProcessing Validation Dataset:\nKeys in /kaggle/input/vulnerabilitycode/VDISC_validate.hdf5: ['CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'functionSource']\nFinal Validation Data Class Distribution:\nClass\n0    1142\n1    1099\n4    1071\n3     535\n2      53\nName: count, dtype: int64\n\nProcessing Test Dataset:\nKeys in /kaggle/input/vulnerabilitycode/VDISC_test.hdf5: ['CWE-119', 'CWE-120', 'CWE-469', 'CWE-476', 'CWE-other', 'functionSource']\nFinal Test Data Class Distribution:\nClass\n0    1142\n1    1099\n4    1071\n3     535\n2      53\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report\nfrom sklearn.preprocessing import label_binarize\nimport numpy as np\nimport pandas as pd\n\n# Custom Dataset class to handle encodings and labels\nclass CodeBERTDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        # Convert inputs and labels to tensors\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Function to tokenize the function source code for training, validation, and test datasets\ndef tokenize_function(df):\n    return tokenizer(\n        df['functionSource'].astype(str).tolist(),\n        padding=True,\n        truncation=True,\n        max_length=512,\n        return_tensors='pt'\n    )\n\n# Load the pre-trained CodeBERT tokenizer\ntokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n\n# Apply the tokenization on the datasets\ntrain_encodings = tokenize_function(df_train_downsampled)\nval_encodings = tokenize_function(df_val_downsampled)\ntest_encodings = tokenize_function(df_test_downsampled)\n\n# Prepare labels\ntrain_labels = df_train_downsampled['Class'].tolist()\nval_labels = df_val_downsampled['Class'].tolist()\ntest_labels = df_test_downsampled['Class'].tolist()\n\n# Create Dataset objects for training, validation, and test datasets\ntrain_dataset = CodeBERTDataset(train_encodings, train_labels)\nval_dataset = CodeBERTDataset(val_encodings, val_labels)\ntest_dataset = CodeBERTDataset(test_encodings, test_labels)\n\n# Define compute_metrics function to calculate accuracy, precision, recall, F1, ROC-AUC, and final classification report\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n\n    # Precision, Recall, F1\n    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n    acc = accuracy_score(p.label_ids, preds)\n\n    # Compute ROC-AUC for multi-class classification\n    label_binarized = label_binarize(p.label_ids, classes=[0, 1, 2, 3, 4])\n    auc_score = roc_auc_score(\n        y_true=label_binarized,\n        y_score=p.predictions,\n        multi_class=\"ovr\"\n    )\n    \n    # Full classification report (output as a dictionary)\n    report_dict = classification_report(p.label_ids, preds, target_names=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'], output_dict=True)\n    \n    # Convert to DataFrame for easy rounding and formatting\n    report_df = pd.DataFrame(report_dict).transpose()\n    report_df = report_df.round(4)  # Round to 4 decimal places\n    \n    print(\"\\nFinal Classification Report (rounded to 4 decimal places):\\n\", report_df)\n\n    return {\n        'accuracy': acc,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'roc_auc': auc_score\n    }\n\n# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy='epoch',\n    per_device_train_batch_size=16,  # Adjust batch size based on available GPU\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,  # Increase to 4-5 epochs if needed\n    learning_rate=2e-5,  # Standard learning rate for fine-tuning transformers\n    logging_dir='./logs',\n    logging_steps=10,\n    save_steps=500,\n    save_total_limit=2,  # Save only the 2 most recent models\n    report_to=\"none\"  # Disable Weights & Biases (wandb) logging\n)\n\n# Load the pre-trained CodeBERT model for classification\nmodel = RobertaForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=5)\n\n# Trainer setup\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,  # Custom training dataset\n    eval_dataset=val_dataset,  # Custom validation dataset\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics  # Metrics function for accuracy, precision, recall, F1, ROC-AUC, classification report\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate the model on the test dataset\nresults = trainer.evaluate(eval_dataset=test_dataset)  # Custom test dataset\nprint(results)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T11:25:29.168056Z","iopub.execute_input":"2024-09-10T11:25:29.168445Z","iopub.status.idle":"2024-09-10T12:26:33.697928Z","shell.execute_reply.started":"2024-09-10T11:25:29.168405Z","shell.execute_reply":"2024-09-10T12:26:33.696845Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a7068992b2f44cf99e491eb0383c941"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b518dcff79d1429b9eef71312817abec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57d65048396d476f8ef8bd1e10bf9f7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d75a2b55d744110af2740a4e85a310f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b336faee35d4121b4773c43b1c96ed1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9617f102616b4acfbd973d7b6ff6674b"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3810' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3810/3810 57:50, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.786000</td>\n      <td>0.659397</td>\n      <td>0.770769</td>\n      <td>0.775599</td>\n      <td>0.770769</td>\n      <td>0.768338</td>\n      <td>0.906717</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.633800</td>\n      <td>0.621639</td>\n      <td>0.791026</td>\n      <td>0.799405</td>\n      <td>0.791026</td>\n      <td>0.789922</td>\n      <td>0.917948</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.463100</td>\n      <td>0.629763</td>\n      <td>0.788462</td>\n      <td>0.787232</td>\n      <td>0.788462</td>\n      <td>0.786479</td>\n      <td>0.913534</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score    support\nClass 0          0.8789  0.8704    0.8746  1142.0000\nClass 1          0.8762  0.7789    0.8247  1099.0000\nClass 2          0.0000  0.0000    0.0000    53.0000\nClass 3          0.7553  0.6000    0.6688   535.0000\nClass 4          0.6108  0.7796    0.6850  1071.0000\naccuracy         0.7708  0.7708    0.7708     0.7708\nmacro avg        0.6242  0.6058    0.6106  3900.0000\nweighted avg     0.7756  0.7708    0.7683  3900.0000\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score   support\nClass 0          0.8845  0.8722    0.8783  1142.000\nClass 1          0.8452  0.8399    0.8425  1099.000\nClass 2          0.6522  0.2830    0.3947    53.000\nClass 3          0.8320  0.5925    0.6921   535.000\nClass 4          0.6526  0.7787    0.7101  1071.000\naccuracy         0.7910  0.7910    0.7910     0.791\nmacro avg        0.7733  0.6733    0.7036  3900.000\nweighted avg     0.7994  0.7910    0.7899  3900.000\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score    support\nClass 0          0.8815  0.8730    0.8773  1142.0000\nClass 1          0.8046  0.8581    0.8305  1099.0000\nClass 2          0.5517  0.3019    0.3902    53.0000\nClass 3          0.7560  0.6486    0.6982   535.0000\nClass 4          0.6961  0.7208    0.7083  1071.0000\naccuracy         0.7885  0.7885    0.7885     0.7885\nmacro avg        0.7380  0.6805    0.7009  3900.0000\nweighted avg     0.7872  0.7885    0.7865  3900.0000\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_85/3756906694.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='244' max='244' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [244/244 01:09]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nFinal Classification Report (rounded to 4 decimal places):\n               precision  recall  f1-score    support\nClass 0          0.8972  0.8555    0.8758  1142.0000\nClass 1          0.7975  0.8562    0.8258  1099.0000\nClass 2          0.5455  0.2264    0.3200    53.0000\nClass 3          0.7908  0.7065    0.7463   535.0000\nClass 4          0.6967  0.7358    0.7157  1071.0000\naccuracy         0.7938  0.7938    0.7938     0.7938\nmacro avg        0.7455  0.6761    0.6967  3900.0000\nweighted avg     0.7947  0.7938    0.7924  3900.0000\n{'eval_loss': 0.6300019025802612, 'eval_accuracy': 0.7938461538461539, 'eval_precision': 0.7946501925723584, 'eval_recall': 0.7938461538461539, 'eval_f1': 0.7924417811062522, 'eval_roc_auc': 0.9090250311250212, 'eval_runtime': 70.2178, 'eval_samples_per_second': 55.541, 'eval_steps_per_second': 3.475, 'epoch': 3.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\n# Plot AUC-ROC curves for each class and save the figure\ndef plot_roc_auc_curve(test_labels, predictions, num_classes=5):\n    test_labels_bin = label_binarize(test_labels, classes=[0, 1, 2, 3, 4])  # Binarize the labels for multi-class ROC\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(test_labels_bin[:, i], predictions[:, i])\n        roc_auc[i] = roc_auc_score(test_labels_bin[:, i], predictions[:, i])\n\n    # Plot ROC curve for each class\n    plt.figure(figsize=(10, 8))\n    colors = ['aqua', 'darkorange', 'cornflowerblue', 'green', 'red']\n    for i in range(num_classes):\n        plt.plot(fpr[i], tpr[i], color=colors[i], lw=2,\n                 label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')\n\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) for each class')\n    plt.legend(loc=\"lower right\")\n\n    # Save the figure to a file\n    output_dir = './roc_auc_plots'\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    plt.savefig(os.path.join(output_dir, 'roc_auc_curve.png'))  # Save the figure as PNG\n    plt.show()\n\n# Compute metrics function with ROC-AUC curve plotting and saving\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n    \n    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n    acc = accuracy_score(p.label_ids, preds)\n    \n    # Compute ROC-AUC for each class using one-vs-rest approach\n    label_binarized = label_binarize(p.label_ids, classes=[0, 1, 2, 3, 4])\n    auc_score = roc_auc_score(\n        y_true=label_binarized,\n        y_score=p.predictions,\n        multi_class=\"ovr\"\n    )\n\n    # Plot ROC curves for each class and save to a file\n    plot_roc_auc_curve(p.label_ids, p.predictions)\n\n    return {\n        'accuracy': acc,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'roc_auc': auc_score\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T12:28:21.935833Z","iopub.execute_input":"2024-09-10T12:28:21.936266Z","iopub.status.idle":"2024-09-10T12:28:21.954350Z","shell.execute_reply.started":"2024-09-10T12:28:21.936224Z","shell.execute_reply":"2024-09-10T12:28:21.953166Z"},"trusted":true},"execution_count":6,"outputs":[]}]}